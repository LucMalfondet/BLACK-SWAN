import pandas as pd
import missingno as msno
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from imblearn.over_sampling import RandomOverSampler
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import auc
from sklearn.model_selection import learning_curve
from sklearn.model_selection import cross_val_score

# Import Dataframe
df = pd.read_csv("/content/Final_psycho_google_3.csv")
msno.matrix(df)

# Data Preparation
df[df["RSI*MASSON"].notnull()]
df["Time"] = pd.to_datetime(df["Time"])
df  = df[df["Time"]>pd.to_datetime("2001-10-31")]
df.isna().sum()
X = df[['Dollar Index','Gold','Close', 'VIX', 'US Bonds 10y']]
y = df['Crisis']
y = y.replace({'Crisis': 0, 'No_Crisis': 1})

# Train/ Test/ Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LOGISTIC REGRESSION
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
logreg_predictions = logreg.predict(X_test)
logreg_accuracy = accuracy_score(y_test, logreg_predictions)
print("Régression logistique - Précision :", logreg_accuracy)
# Classification report
print("Rapport de classification - Régression logistique:")
print(classification_report(y_test, logreg_predictions))
# Confusion Matrix
print("Matrice de confusion - Régression logistique:")
print(confusion_matrix(y_test, logreg_predictions))
# Calculer les scores de probabilité pour les classes positives
y_pred_prob = logreg.predict_proba(X_test)[:, 1]
# AUC-ROC Cruve
auc_roc = roc_auc_score(y_test, y_pred_prob)

# RANDOM FOREST
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
rf_predictions = rf.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_predictions)
print("Random Forest - Précision :", rf_accuracy)
# Classification report
print("Rapport de classification - Régression logistique:")
print(classification_report(y_test, rf_predictions))
# Matrice de confusion
print("Matrice de confusion - Régression logistique:")
print(confusion_matrix(y_test, rf_predictions))
# Calculer les scores de probabilité pour les classes positives
y_pred_prob = rf.predict_proba(X_test)[:, 1]
# Calculer l'AUC-ROC
auc_roc = roc_auc_score(y_test, y_pred_prob)
print("Aire sous la courbe ROC (AUC-ROC) :", auc_roc)

# ADABOOST
adaboost = AdaBoostClassifier()
adaboost.fit(X_train, y_train)
adaboost_predictions = adaboost.predict(X_test)
adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)
print("AdaBoost - Précision :", adaboost_accuracy)
# Classification report
print("Rapport de classification - Régression logistique:")
print(classification_report(y_test, adaboost_predictions))
# Matrice de confusion
print("Matrice de confusion - Régression logistique:")
print(confusion_matrix(y_test, adaboost_predictions))
# Calculer les scores de probabilité pour les classes positives
y_pred_prob = adaboost.predict_proba(X_test)[:, 1]
# Calculer l'AUC-ROC
auc_roc = roc_auc_score(y_test, y_pred_prob)
print("Aire sous la courbe ROC (AUC-ROC) :", auc_roc)

# XGBoost
xgboost = xgb.XGBClassifier()
xgboost.fit(X_train, y_train)
xgboost_predictions = xgboost.predict(X_test)
xgboost_accuracy = accuracy_score(y_test, xgboost_predictions)
print("XGBoost - Précision :", xgboost_accuracy)
# Classification report
print("Rapport de classification - Régression logistique:")
print(classification_report(y_test, xgboost_predictions))
# Matrice de confusion
print("Matrice de confusion - Régression logistique:")
print(confusion_matrix(y_test, xgboost_predictions))
# Calculer les scores de probabilité pour les classes positives
y_pred_prob = xgboost.predict_proba(X_test)[:, 1]
# Calculer l'AUC-ROC
auc_roc = roc_auc_score(y_test, y_pred_prob)
print("Aire sous la courbe ROC (AUC-ROC) :", auc_roc)


